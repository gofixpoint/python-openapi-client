# coding: utf-8

"""
    fixpoint/v1/service.proto

    No description provided (generated by Openapi Generator https://github.com/openapitools/openapi-generator)

    The version of the OpenAPI document: version not set
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


import unittest

from fixpoint_openapi.models.v1_multi_llm_chat_completion import V1MultiLLMChatCompletion

class TestV1MultiLLMChatCompletion(unittest.TestCase):
    """V1MultiLLMChatCompletion unit test stubs"""

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def make_instance(self, include_optional) -> V1MultiLLMChatCompletion:
        """Test V1MultiLLMChatCompletion
            include_option is a boolean, when False only required
            params are included, when True both required and
            optional params are included """
        # uncomment below to create an instance of `V1MultiLLMChatCompletion`
        """
        model = V1MultiLLMChatCompletion()
        if include_optional:
            return V1MultiLLMChatCompletion(
                id = '',
                primary_external_id = '',
                model_names = [
                    ''
                    ],
                tracing = fixpoint_openapi.models.a_note_on_sessions,_traces,_and_spans:.A note on sessions, traces, and spans:(
                    session_id = '', 
                    trace_id = '', 
                    span_id = '', 
                    parent_span_id = '', ),
                completion = fixpoint_openapi.models.v1_chat_completion.v1ChatCompletion(
                    id = '', 
                    external_id = '', 
                    model = '', 
                    tracing = fixpoint_openapi.models.a_note_on_sessions,_traces,_and_spans:.A note on sessions, traces, and spans:(
                        session_id = '', 
                        trace_id = '', 
                        span_id = '', 
                        parent_span_id = '', ), 
                    choices = [
                        fixpoint_openapi.models.v1_chat_completion_choice.v1ChatCompletionChoice(
                            index = 56, 
                            message = fixpoint_openapi.models.v1_output_message.v1OutputMessage(
                                role = '', 
                                content = '', 
                                tool_calls = [
                                    fixpoint_openapi.models.v1_tool_call.v1ToolCall(
                                        id = '', 
                                        type = '', 
                                        function = fixpoint_openapi.models.tool_call_function.ToolCallFunction(
                                            name = '', 
                                            arguments = '', ), )
                                    ], ), 
                            finish_reason = '', )
                        ], 
                    usage = fixpoint_openapi.models.v1_chat_completion_usage.v1ChatCompletionUsage(
                        prompt_tokens = 56, 
                        completion_tokens = 56, 
                        total_tokens = 56, ), ),
                mode = 'MODE_UNSPECIFIED'
            )
        else:
            return V1MultiLLMChatCompletion(
        )
        """

    def testV1MultiLLMChatCompletion(self):
        """Test V1MultiLLMChatCompletion"""
        # inst_req_only = self.make_instance(include_optional=False)
        # inst_req_and_optional = self.make_instance(include_optional=True)

if __name__ == '__main__':
    unittest.main()
